# 11장 HTTP/1.X

> HTTP/1.0 최적화 전략에 대한 논의는 매우 간단하다:
> 모든 HTTP/1.0 배포는 HTTP/1.1로 업그레이드해야 한다는 것이다.

HTTP/1.1은 HTTP/1.0의 성능 문제를 개선하기 위해 여러 가지 핵심 기능과 최적화 방안을 도입했습니다. 대표적인 성능 향상 기능으로는 다음과 같은 것들이 있습니다:

- **지속 연결(Persistent Connection, Keep-Alive)**: 하나의 TCP 연결을 여러 요청에 재사용하여 연결 설정 오버헤드를 줄이고, 웹 페이지 로딩 속도를 개선합니다.
- **청크 전송 인코딩(Chunked Transfer Encoding)**: 서버가 데이터를 스트리밍 방식으로 전송할 수 있게 하여 대용량 응답 처리에 유리합니다.
- **요청 파이프라이닝(Request Pipelining)**: 클라이언트가 응답을 기다리지 않고 여러 요청을 연속적으로 보낼 수 있도록 지원하지만, 실제로는 브라우저의 지원 부족 등으로 널리 사용되지는 못했습니다
- **바이트 범위 요청(Byte Serving)**: 파일의 일부만 요청할 수 있어 대용량 파일의 부분 다운로드가 가능합니다.
- **캐싱 메커니즘 개선**: 더 명확하고 효율적인 캐시 정책을 적용할 수 있도록 헤더와 동작이 개선되었습니다.

이러한 HTTP/1.1의 다양한 성능 개선 기능에 대한 자세한 기술적 내용은 **David Gourley와 Brian Totty의 『HTTP: The Definitive Guide』** ([HTTP 완벽 가이드, 600p 2002](https://www.yes24.com/Product/Goods/15381085?Acode=101))에서 더 깊이 있게 다루고 있습니다. 또한, 실질적인 웹 성능 최적화 전략에 대해서는 **Steve Souders의 『High Performance Web Sites』**([웹 사이트 최적화 기법, 140p 2007](https://www.yes24.com/product/goods/2961377))가 매우 유용한 14가지 규칙을 제시하고 있습니다. 그 중 다음과 같은 실질적인 전략들이 권장됩니다:

- **DNS 조회 최소화**: 도메인 수를 줄여 불필요한 네트워크 지연을 줄입니다.
- **HTTP 요청 수 줄이기**: 페이지에 불필요한 리소스를 제거해 요청 자체를 줄입니다.
- **CDN 사용**: 사용자와 가까운 서버에서 데이터를 제공해 지연을 최소화합니다.
- **Expires 헤더 및 ETag(entity tag) 설정**: 캐시를 적극 활용해 동일 리소스의 반복 요청을 방지합니다.
- **Gzip 압축 사용**: 텍스트 기반 자산을 압축해 전송 데이터 크기를 60~80%까지 줄입니다.
- **HTTP 리다이렉트 최소화**: 불필요한 리다이렉트는 추가적인 DNS 조회와 연결 지연을 유발하므로 피해야 합니다.

하지만 HTTP/1.1의 일부 기능(예: 파이프라이닝)은 실제 환경에서는 한계가 있었고, 헤드-오브-라인 블로킹(HOL Blocking) 등 구조적 한계로 인해 개발자들은 도메인 샤딩, 파일 합치기, 이미지 스프라이팅, 인라인 처리 등 다양한 우회 최적화 기법을 사용해 왔습니다. 이러한 기법들은 HTTP/1.1의 한계를 보완하기 위한 임시방편이었으며, 근본적인 해결은 차세대 프로토콜(HTTP/2 등)에서 이뤄지고 있습니다

> 사례

WWDC 2012에서 Joshua Graessley는 HTTP 최적화의 효과를 보여주는 훌륭한 사례를 소개했습니다. Apple 엔지니어들은 iTunes에서 HTTP keepalive와 파이프라이닝을 통해 기존 TCP 연결을 더 잘 재사용함으로써, 느린 네트워크 환경에서 사용자 경험이 3배(300%) 향상되는 성과를 얻었습니다.

## Benefits of Keepalive Connections

> HTTP/1.1에서 도입된 주요 성능 개선 중 하나
> 한 번 맺은 TCP 연결을 여러 HTTP 요청과 응답에 재사용

### 기존 방식

HTML과 CSS 두 개의 작은 리소스를 받아올 때,
각각의 요청이 두 번의 네트워크 왕복(1회는 핸드셰이크, 1회는 요청/응답)에 서버 처리 시간을 더해 총 소요 시간이 결정됩니다.
서버 처리 시간이 아무리 빨라도, 연결을 새로 맺는 오버헤드는 항상 고정 비용으로 남습니다.
![keepalive_1](https://hpbn.co/assets/diagrams/84cf0f29175e4b11a2343e73105637c5.svg)

### Keepalive 적용

Keepalive를 사용하면 첫 요청만 두 번의 RTT가 필요하고, 이후 요청들은 각 한 번의 RTT만으로 처리할 수 있습니다.
실제 웹 페이지는 평균적으로 90개 이상의 리소스를 포함하고 있기 때문에, Keepalive를 통해 절감되는 지연 시간은 매우 커집니다. 여러 초 단위의 성능 개선도 가능합니다.
![keepalive_2](https://hpbn.co/assets/diagrams/cf6057a54f005a288d832d293965ee0d.svg)

## HTTP Pipelining

HTTP 파이프라이닝(HTTP Pipelining)은 HTTP/1.1에서 도입된 성능 최적화 기법으로, 하나의 지속 연결(Keepalive)을 통해 여러 HTTP 요청을 연속적으로 보내고, 서버가 받은 순서대로 응답을 반환하는 방식입니다

기존에는 클라이언트가 요청을 보내고, 서버로부터 응답을 모두 받은 후에야 다음 요청을 보낼 수 있었습니다(FIFO 방식). 파이프라이닝은 응답을 기다리지 않고 여러 요청을 한꺼번에 보내 서버가 **미리 처리**할 수 있도록 합니다. 이를 통해 네트워크 왕복 시간(RTT)을 추가로 절감할 수 있습니다. 실제 예시에서는 파이프라이닝 적용만으로 전체 지연 시간이 40%까지 감소할 수 있습니다
![pipelining_1](https://hpbn.co/assets/diagrams/c4a166135379abdf29c534f3da880d5e.svg)

**하지만** 서버가 여러 요청을 병렬로 처리하더라도, HTTP/1.x 프로토콜의 제약 때문에 응답은 반드시 요청 순서대로 전송해야 합니다. 예를 들어, 두 번째 요청의 처리가 더 빨리 끝나더라도, 첫 번째 요청의 응답이 끝날 때까지 두 번째 응답은 대기해야 합니다. 이로 인해 네트워크 자원이 비효율적으로 사용되고, 특정 요청이 지연되면 뒤따르는 모든 요청도 함께 지연되는 헤드 오브 라인 블로킹(Head-of-Line Blocking, HOLB) 문제가 발생합니다.

![pipelining_2](https://hpbn.co/assets/diagrams/9e0502a36ccd2bdd00eb09e1e6cb3b6d.svg)

- **실제 도입의 어려움**: 파이프라이닝은 이론적으로는 지연 시간을 크게 줄일 수 있지만, 다음과 같은 현실적 한계로 인해 실제로는 널리 쓰이지 못했습니다.

  - 하나의 응답이 지연되면 뒤따르는 모든 요청이 함께 지연되는 구조적 문제
  - 서버가 응답을 버퍼링해야 하므로 리소스 소모 및 보안 취약점 노출 가능성
  - 일부 중간 장비가 파이프라이닝을 지원하지 않거나, 연결을 끊어버릴 수 있음

- **결론**: 이러한 이유로 HTTP 파이프라이닝은 실제 웹 브라우저에서는 대부분 비활성화되어 있고, 신뢰할 수 있는 성능 개선책으로 간주되지 않습니다. 따라서 HTTP/2에서는 멀티플렉싱(여러 요청과 응답을 순서와 무관하게 동시에 처리) 기능이 도입되어 이러한 한계를 근본적으로 해결하였습니다.

## Using Multiple TCP Connections

HTTP/1.x에서는 멀티플렉싱(한 연결에서 여러 요청·응답을 동시에 처리)이 불가능하기 때문에, 브라우저는 성능 향상을 위해 한 도메인(호스트)당 여러 개의 TCP 연결을 동시에 여는 방식을 사용합니다. 실제로 대부분의 최신 브라우저는 한 호스트당 최대 6개의 병렬 연결을 엽니다.

### 여러 TCP 연결을 사용하는 장점

- 클라이언트와 서버가 최대 6개의 요청을 동시에 주고받을 수 있어, 단일 연결보다 훨씬 빠른 리소스 로딩이 가능합니다.
- 각 연결마다 TCP 혼잡 윈도우(cwnd)가 따로 적용되어, 초기 데이터 전송량이 늘어나 네트워크 대역폭을 더 효과적으로 활용할 수 있습니다.

### 단점

- 클라이언트, 서버, 중간 장비 모두에서 추가 소켓(연결)으로 인한 메모리·CPU 자원 소모가 증가합니다.
- 여러 연결이 네트워크 대역폭을 두고 경쟁하게 되어, 오히려 네트워크 효율이 떨어질 수 있습니다.
- 소켓 관리가 복잡해지고, 개발·운영 비용이 증가합니다.
- 여러 연결을 열어도 병렬성에는 한계가 있으며, **근본적으로 HTTP/1.x의 구조적 한계를 완전히 해결하지는 못합니다.**

### 이런 방식을 쓸 수밖에 없는 이유

- HTTP/1.x 프로토콜의 한계(멀티플렉싱 부재)로 인한 우회책입니다.
- TCP의 초기 혼잡 윈도우(cwnd) 크기가 작을 때 이를 보완하기 위한 목적도 있습니다.
- TCP 윈도우 스케일링을 지원하지 않는 클라이언트 환경에 대한 대응책이기도 합니다.

### 브라우저가 6개로 제한한 이유

- 연결 수가 많아질수록 병렬성은 증가하지만, 그만큼 클라이언트와 서버의 자원 소모도 커집니다.
- 6개는 성능과 리소스 소모 사이의 현실적인 절충안으로, 일부 사이트에는 충분할 수 있지만, 리소스가 많은 사이트에는 부족할 수 있습니다.

### 도메인 샤딩(domain sharding)과의 관계

- 6개 연결 제한을 우회하기 위해 여러 서브도메인(예: shard1.example.com, shard2.example.com)으로 리소스를 분산하는 도메인 샤딩 기법이 등장했습니다.
- 하지만 샤딩은 추가적인 DNS 조회, 더 많은 TCP 연결, 관리 복잡성 등 또 다른 비용과 단점을 유발합니다.

### 결론

- 여러 TCP 연결을 여는 방식은 HTTP/1.x의 구조적 한계를 극복하기 위한 임시방편일 뿐, 장기적으로는 **HTTP/2 이상**의 멀티플렉싱 지원 프로토콜로의 전환이 권장됩니다

## Domain Sharding

## 도메인 샤딩(Domain Sharding) 요약

**도메인 샤딩**은 HTTP/1.x 환경에서 웹 페이지의 리소스(이미지, JS, CSS 등)를 여러 개의 하위 도메인(예: shard1.example.com, shard2.example.com)에 분산해 제공함으로써, 브라우저가 각 도메인별로 최대 동시 연결 수(보통 6개) 제한을 우회하고 더 많은 리소스를 병렬로 다운로드할 수 있도록 하는 최적화 기법입니다.

### 왜 필요한가?

- 현대 웹 페이지는 평균적으로 90개 이상의 리소스를 포함하고 있습니다.
- 모든 리소스를 하나의 도메인에서 제공하면 브라우저의 동시 연결 제한(예: 6개)에 걸려 대기열이 생기고, 전체 로딩 속도가 느려집니다.
- 여러 하위 도메인으로 리소스를 분산하면 병렬 다운로드가 가능해져 페이지 로딩 속도가 빨라집니다.

![domain_sharding_1](https://hpbn.co/assets/diagrams/a2283460ffae3026632ff33c24bc5462.png)

### 동작 방식

- 여러 하위 도메인을 생성하고, 각 도메인에 리소스를 분산 배치합니다.
- 브라우저는 각 도메인별로 동시 연결을 최대치까지 열기 때문에, 전체적으로 더 많은 리소스를 동시에 내려받을 수 있습니다.
- 실제로는 여러 하위 도메인이 같은 IP로 연결되어도, 브라우저는 도메인 이름 기준으로 연결 제한을 적용합니다.

### 단점 및 한계

- **DNS 조회 증가**: 하위 도메인마다 별도의 DNS 조회가 필요해 초기 로딩 시간이 늘어날 수 있습니다.
- **TCP 연결 오버헤드**: 추가로 생성되는 각 연결마다 TCP 핸드셰이크 및 slow-start가 발생해 리소스 소모가 커집니다.
- **관리 복잡성**: 리소스 분배, 도메인 관리 등 추가적인 작업이 필요합니다.
- **과도한 샤딩의 역효과**: 너무 많은 샤드를 만들면 오히려 성능이 저하될 수 있습니다. 일반적으로 2~4개 정도가 권장됩니다.
- **HTTPS 환경에서 비용 증가**: 각 도메인마다 TLS 핸드셰이크가 추가로 필요해 오버헤드가 더 커집니다.

### 결론 및 권장 사항

- 도메인 샤딩은 HTTP/1.x의 구조적 한계(동시 연결 제한)를 우회하기 위한 임시방편입니다.
- HTTP/2 이상에서는 한 연결에서 멀티플렉싱이 지원되므로, 도메인 샤딩이 필요하지 않으며 오히려 성능에 해로울 수 있습니다.
- 도메인 샤딩을 적용할 때는 최소한의 샤드로 시작해, 실제 성능 개선 효과를 측정하며 점진적으로 조정하는 것이 바람직합니다.

이러한 최적화 기법들은 HTTP/1.1의 한계를 보완하기 위한 임시방편이며, 궁극적으로는 **HTTP/2**와 같은 차세대 프로토콜로의 전환이 장기적인 해결책입니다.

## Measuring and Controlling Protocol Overhead

### HTTP/1.x의 오버헤드란?

- HTTP/0.9는 매우 단순한 ASCII 요청만을 사용해 오버헤드가 거의 없었습니다.
- HTTP/1.0부터 요청과 응답에 헤더가 추가되면서 메타데이터 전송이 가능해졌고, HTTP/1.1에서는 이 구조가 표준화되어 확장성과 호환성이 높아졌습니다.
- 오늘날 브라우저가 생성하는 HTTP 요청에는 보통 500~800바이트의 헤더(유저 에이전트, Accept, 캐시, 전송 관련 헤더 등)가 추가됩니다. 여기에 쿠키까지 포함되면, 실제 오버헤드는 요청 하나당 수 킬로바이트에 달할 수 있습니다.

### 오버헤드의 문제점

- 헤더는 대부분 텍스트로 전송되고, **압축되지 않아 반복적이고 불필요한 데이터**가 많습니다.
- 특히 API 기반 웹앱에서는 페이로드(실제 데이터)보다 오버헤드가 훨씬 큰 경우도 있습니다. 예시로, 15바이트의 JSON 메시지에 352바이트의 헤더가 붙어 96%가 오버헤드인 상황도 발생합니다.
- RFC 2616(HTTP/1.1)은 헤더 크기 제한을 명시하지 않지만, 실제로는 서버/프록시가 8KB 또는 16KB 제한을 두는 경우가 많습니다.

### 오버헤드 최소화 전략

- **불필요한 요청/헤더/쿠키 제거:** 쿠키 등 불필요한 헤더를 줄이면 네트워크 지연과 오버헤드를 크게 줄일 수 있습니다.
- **리소스 결합(Concatenation, Spriting):** 여러 JS/CSS 파일을 하나로 합치거나, 여러 이미지를 스프라이트로 묶어 요청 수 자체를 줄이면 각 요청에 반복적으로 붙는 오버헤드를 크게 감소시킬 수 있습니다.
- **인라인(Inline):** 크기가 작은 리소스(1~2KB 이하)는 HTML 문서에 직접 포함시켜 별도 요청을 없애는 것도 방법입니다. 단, 인라인 리소스는 캐시가 불가능하고, base64 인코딩 시 33%의 추가 오버헤드가 발생합니다.
- **요청 수 자체 최소화:** 가장 좋은 최적화는 아예 요청을 만들지 않는 것입니다. 필요 없는 리소스는 제거하고, 여러 리소스를 하나로 묶어 전송하면 오버헤드를 줄일 수 있습니다.

### 한계와 주의점

- 리소스 결합이나 인라인은 캐시 관리가 어려워질 수 있고, 업데이트가 잦은 리소스에는 오히려 비효율적일 수 있습니다.
- 오버헤드 최소화와 캐시 효율성, 유지보수성 사이에서 균형을 맞추는 것이 중요합니다.

### 결론

- HTTP/1.x의 구조적 한계(비압축 헤더, 요청별 오버헤드)는 성능 저하의 원인이 될 수 있으므로, 오버헤드 측정과 최소화는 웹 성능 최적화의 핵심입니다.
- HTTP/2 이상에서는 헤더 압축 등으로 이 문제를 근본적으로 개선하고 있습니다.

## Concatenation and Spriting

**Concatenation(파일 결합)과 Spriting(이미지 스프라이트)**는 HTTP/1.x의 구조적 한계(특히 요청 수가 많을 때 발생하는 오버헤드와 파이프라이닝 미지원)를 극복하기 위해 널리 사용된 애플리케이션 계층의 최적화 기법입니다.

### 주요 개념과 효과

- **Concatenation(파일 결합)**

  - 여러 개의 JavaScript 또는 CSS 파일을 하나로 합쳐서 한 번의 요청으로 내려받게 하는 방식입니다.
  - 실행 순서만 보장되면, 여러 스크립트나 스타일 파일을 안전하게 하나로 묶을 수 있습니다.

- **Spriting(이미지 스프라이트)**
  - 여러 이미지를 하나의 큰 이미지로 합치고, CSS를 이용해 필요한 부분만 화면에 표시하는 기법입니다.

#### 두 기법의 장점

- **프로토콜 오버헤드 감소**: 각 파일마다 발생하는 HTTP 헤더, 쿠키 등 요청 오버헤드를 한 번만 내게 되어 전체 네트워크 트래픽이 크게 줄어듭니다.
- **애플리케이션 계층 파이프라이닝**: 여러 리소스를 하나의 요청/응답으로 묶어 전송함으로써, 마치 HTTP 파이프라이닝이 지원되는 것처럼 연속적으로 데이터를 받을 수 있습니다.

### 단점 및 주의사항

- **캐시 효율 저하**: 여러 파일을 하나로 합치면, 그 중 일부만 변경되어도 전체 파일을 다시 내려받아야 하므로 캐시 효율이 떨어집니다.
- **불필요한 데이터 전송**: 실제로 필요하지 않은 리소스까지 함께 받아야 할 수 있습니다.
- **업데이트 비용 증가**: 스프라이트 이미지나 번들 파일 중 일부만 바뀌어도 전체 파일을 다시 내려받아야 하므로, 빈번한 변경이 있는 경우 비효율적입니다.
- **메모리 사용량 증가**: 스프라이트 이미지는 전체 이미지를 메모리에 올려야 하므로, 실제로 표시되는 영역이 작아도 메모리 부담이 커질 수 있습니다.
- **실행 지연**: JavaScript와 CSS는 전체 파일이 모두 다운로드되어야만 실행 및 렌더링이 시작됩니다. 따라서 파일이 클수록 첫 화면 표시가 늦어질 수 있습니다.

### 결론

Concatenation과 Spriting은 HTTP/1.x의 요청 오버헤드와 파이프라이닝 미지원 문제를 우회하기 위한 대표적인 최적화 방법입니다. 이 기법들은 네트워크 효율을 크게 높일 수 있지만, 캐시 관리, 업데이트, 메모리, 실행 지연 등 여러 부작용이 있으므로, 실제 적용 시에는 각 애플리케이션의 특성에 맞춰 신중하게 사용하고, 효과를 측정하며 적용 범위를 결정하는 것이 중요합니다.

> 브라우저 이미지 크기 크기

이미지는 브라우저에서 디코딩된 후 메모리에 RGBA 비트맵 형태로 저장되며, 픽셀 하나당 4바이트(빨강, 초록, 파랑, 알파 각각 1바이트)를 차지합니다.

- 예를 들어, 800×600 크기의 비트맵 이미지는
- 800 × 600 × 4 = 1,920,000 바이트 ≈ 약 1.83MB의 메모리를 사용하게 됩니다.

## Resource Inlining

## 리소스 인라이닝(Resource Inlining) 요약

리소스 인라이닝은 HTTP/1.x에서 네트워크 요청 수를 줄이기 위해 널리 사용된 최적화 기법입니다. 이는 자바스크립트, CSS, 이미지, 오디오, PDF 등 다양한 리소스의 내용을 **HTML 문서 내에 직접 포함**시키는 방식입니다. 예를 들어, `<script>`나 `<style>` 태그로 JS/CSS 코드를 직접 넣거나, 이미지·오디오·PDF 등은 data URI(예: `data:image/gif;base64,...`) 형태로 인라인할 수 있습니다.

### 장점

- **요청 수 감소**: 별도의 네트워크 요청 없이 리소스를 한 번에 내려받을 수 있어, RTT(왕복 지연)와 프로토콜 오버헤드가 줄어듭니다.
- **초소형 리소스에 효과적**: 보통 1~2KB 이하의 작은 리소스는 오히려 HTTP 헤더 등 오버헤드가 더 클 수 있으므로 인라이닝이 효율적입니다.

### 단점 및 한계

- **캐싱 불가**: 인라인된 리소스는 개별적으로 캐시될 수 없고, HTML 문서 전체가 변경될 때마다 다시 받아야 합니다. 여러 페이지에서 동일한 리소스를 인라인하면, 각 페이지마다 중복 전송이 발생해 전체 트래픽이 증가합니다.
- **업데이트 불편**: 인라인 리소스가 변경되면 해당 리소스를 포함한 모든 페이지를 다시 내려받아야 하므로, 업데이트가 잦은 리소스에는 비효율적입니다.
- **base64 오버헤드**: 텍스트가 아닌 리소스(이미지 등)는 base64 인코딩을 사용해야 하며, 이 과정에서 원본 대비 33% 용량이 늘어납니다.
- **브라우저 제한**: 일부 브라우저(예: IE8)는 data URI 크기에 제한(32KB 등)을 둘 수 있습니다.

### 적용 기준

- **특정 페이지에서만 사용되는 아주 작은 리소스**: 인라이닝 권장
- **여러 페이지에서 반복 사용되거나, 자주 변경되는 리소스**: 별도 파일로 분리해 캐싱 활용
- **오버헤드와 캐시 효율성, 유지보수성**: 상황에 따라 균형 있게 적용 필요

### 결론

리소스 인라이닝은 HTTP/1.x의 구조적 한계(요청 오버헤드, RTT 등)를 우회하기 위한 임시방편입니다. 작은 리소스에는 효과적이지만, 캐시와 유지보수, 업데이트 측면에서 주의가 필요하므로, 각 리소스의 특성과 사용 패턴에 따라 신중하게 적용해야 합니다

## 논의 주제

Keep-alive는 무조건 있으면 좋은 설정으로 보이는데 문제가 발생한 사례가 있나요?

- keep-alive를 너무 오래 유지하면 오히려 리소스를 낭비한 경험
- 그럼 연결 유지 시간 설정은 어떻게 하는 게 최적일까?
- [글1](https://jeongchul.tistory.com/m/758?category=1123718), [글2](https://haon.blog/haon/infra/nginx/keep-alive/)
